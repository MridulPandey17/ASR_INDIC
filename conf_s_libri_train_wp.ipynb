{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e537e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics.text.wer import WordErrorRate\n",
    "from torchmetrics.text.cer import CharErrorRate\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "\n",
    "# Support Libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from itertools import groupby\n",
    "\n",
    "# Python Scripts\n",
    "from conf_model import ConformerEncoder, LSTMDecoder\n",
    "from conf_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135807bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU Devices : 1\n",
      "Using devices : [0]\n"
     ]
    }
   ],
   "source": [
    "total_devices = torch.cuda.device_count()\n",
    "print(f\"Available GPU Devices : {total_devices}\")\n",
    "DEVICES = [i for i in range(0,total_devices)]\n",
    "print(f\"Using devices : {DEVICES}\")\n",
    "DEVICE = f\"cuda:{DEVICES[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded70e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BS = 20*len(DEVICES)\n",
    "TEST_BS = 20*len(DEVICES)\n",
    "EPOCHS = 1000\n",
    "NUM_WORKERS = 4*len(DEVICES)\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98428e4e",
   "metadata": {},
   "source": [
    "metadata_path = \"/media/rathna/New Volume/datasets/LJSpeech-1.1/metadata.tsv\"\n",
    "metadata = pd.read_csv(metadata_path, sep = '\\t', header = None)\n",
    "\n",
    "metadata = metadata[metadata[2]<=16].reset_index(drop=True)\n",
    "\n",
    "metadata[0] = \"/media/rathna/New Volume/datasets/LJSpeech-1.1/wavs/\" + metadata[0]\n",
    "\n",
    "metadata = metadata.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e31f85c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        0  \\\n",
      "0       /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "1       /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "2       /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "3       /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "4       /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "...                                                   ...   \n",
      "124491  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "124492  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "124493  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "124494  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "124495  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "\n",
      "                                                        1       2      3  \n",
      "0       or my dread of its doing them both harm and i ...  15.765  16000  \n",
      "1       when about a fortnight old however they genera...  13.260  16000  \n",
      "2       the real evils indeed of emmas situation were ...  14.530  16000  \n",
      "3       this was approved of but postponed for a day o...  11.745  16000  \n",
      "4       steel blue and mysterious edward povey surveyi...  14.925  16000  \n",
      "...                                                   ...     ...    ...  \n",
      "124491  and they will take thee alive and then there i...  14.850  16000  \n",
      "124492  and i taught them because they were pleasing u...  15.890  16000  \n",
      "124493  some days later while stalking his prey in the...  15.060  16000  \n",
      "124494  was after all of trifling consequence to him a...  15.405  16000  \n",
      "124495  from lake ontario there is an old river bed ru...  13.970  16000  \n",
      "\n",
      "[124496 rows x 4 columns]\n",
      "                                                      0  \\\n",
      "0     /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "1     /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "2     /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "3     /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "4     /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "...                                                 ...   \n",
      "2418  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "2419  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "2420  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "2421  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "2422  /media/rathna/New Volume/datasets/Librispeech/...   \n",
      "\n",
      "                                                      1          2      3  \n",
      "0                           thus idleness is the mother   3.185000  16000  \n",
      "1     there is of course a difference between knowin...  11.845000  16000  \n",
      "2          george montfichet will never forget this day   2.934938  16000  \n",
      "3                            alexander did not sit down   2.110000  16000  \n",
      "4     humpy dumpy fell downstairs and yet he married...   5.365000  16000  \n",
      "...                                                 ...        ...    ...  \n",
      "2418                     ye may not see his worship now   2.850000  16000  \n",
      "2419       tis now winter out of doors thought the tree   4.715000  16000  \n",
      "2420  women can hide their pain better than we men a...   9.345000  16000  \n",
      "2421  the head and chief of the riot the nottingham ...   5.355000  16000  \n",
      "2422  he felt a tremor run through the slender yello...   3.590000  16000  \n",
      "\n",
      "[2423 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "metadata_train = pd.read_csv(\"/media/rathna/New Volume/datasets/Librispeech/metadata_train_clean.tsv\", sep = '\\t', header = None)\n",
    "metadata_dev = pd.read_csv(\"/media/rathna/New Volume/datasets/Librispeech/metadata_test_clean.tsv\", sep = '\\t', header = None)\n",
    "\n",
    "metadata_train = metadata_train[metadata_train[2]<=16].reset_index(drop=True)\n",
    "\n",
    "\n",
    "metadata_train = metadata_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(metadata_train)\n",
    "\n",
    "metadata_dev = metadata_dev[metadata_dev[2]<=16].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "metadata_dev = metadata_dev.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(metadata_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff674169",
   "metadata": {},
   "source": [
    "USE THIS TO BUILD THE TOKENIZER AND MARK DOWN BEFORE RUNNING THE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d75ac76",
   "metadata": {},
   "source": [
    "import tokenizers\n",
    "import os\n",
    "\n",
    "vocab_size = 1004 #CAN SPECIFY ANY MAXIMUM VALUE\n",
    "tokenizer_type = \"wpe\"\n",
    "dst_folder = \"/media/rathna/New Volume/word_piece\"\n",
    "text_path = \"/media/rathna/New Volume/word_piece/libri_text_460.txt\"\n",
    "dataset = \"libri\"\n",
    "tokenizer_dir = os.path.join(dst_folder, 'tokenizer_{}_{}_v{}').format(dataset, tokenizer_type, vocab_size)\n",
    "\n",
    "if not os.path.exists(tokenizer_dir):\n",
    "    os.makedirs(tokenizer_dir)\n",
    "\n",
    "tokenizer = tokenizers.BertWordPieceTokenizer(lowercase=False) #if true, treats upper and lower case as separate tokens\n",
    "\n",
    "tokenizer.train(text_path, vocab_size=vocab_size)\n",
    "tokenizer.save_model(tokenizer_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651570d0",
   "metadata": {},
   "source": [
    "del tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38ae2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '##u', '##g', '##i', '##n', '##o', '##e', '##c', '##t', '##h', '##a', '##r', '##l', '##s', '##v', '##k', '##b', '##d', '##m', '##f', '##p', '##w', '##y', '##z', '##q', '##x', '##j', 'th', 'the', '##er', '##nd', '##in', '##ed', '##ou', '##at', '##en', 'and', '##es', '##or', '##on', 'of', 'to', '##is', '##ing', '##ar', '##it', '##an', '##as', '##ll', 'in', '##re', 'wh', '##om', 'he', 'be', 'ha', '##le', '##ot', '##ic', '##ut', '##ow', 'it', '##ld', 'that', '##ly', 'was', 'sh', '##gh', '##se', '##id', 'on', '##ve', '##ent', '##et', '##im', '##st', '##ion', '##ce', '##ir', '##ith', 'for', 'you', '##al', 'as', '##ay', 'his', '##ur', 'with', '##ter', 'st', '##ch', '##ver', 're', '##ad', 'her', 'an', '##ght', 'is', 'not', 'had', '##am', 'at', '##ct', '##her', '##oo', 'but', '##ess', '##ould', 'fr', 'se', 'pr', 'she', 'we', 'sa', 'su', 'so', '##ill', '##ain', 'him', '##ight', '##ere', 'me', '##all', '##il', '##ke', 'they', '##est', 'de', 'all', '##ich', 'ch', 'by', 'con', '##pp', 'ne', 'my', 'this', '##ome', '##us', 'have', 'li', '##ck', 'which', '##ore', '##ri', '##ul', 'do', 'from', '##th', '##ge', 'up', '##ard', 'or', '##ra', 'were', 'ex', '##ant', 'said', '##nt', 'one', '##os', 'no', '##pe', '##ble', '##ation', 'man', 'who', 'al', '##ers', 'there', '##ous', 'them', '##and', '##ust', '##ie', 'fe', '##ame', 'when', 'their', '##ist', '##ind', '##ast', '##ood', '##lf', '##ong', 'are', '##our', '##em', 'go', '##art', '##out', 'le', 'kn', '##if', 'com', 'would', '##ate', '##ound', 'int', '##ol', 'wor', 'if', 'ab', '##ak', '##op', 'out', '##um', 'br', 'will', '##un', 'mis', 'what', '##ish', '##ap', 'en', '##ough', '##one', '##la', 'ar', '##itt', 'been', '##own', '##reat', 'un', 'tr', '##ity', '##ig', '##ook', '##ive', '##ven', 'then', 'af', 'ro', '##ort', 'sp', 'tw', '##ost', 'qu', '##self', 'fa', '##ery', 'ag', '##el', 'could', 'am', 'im', 'some', '##ake', '##ure', 'any', '##ther', '##nder', '##ence', 'more', 'tim', 'into', '##ep', '##ose', 'ever', '##ies', '##ry', '##fe', '##ag', '##au', '##qu', 'your', '##ved', 'bo', 'other', 'its', 'now', '##ance', 'cl', 'can', 'very', '##ach', 'gr', 'than', '##able', '##ine', '##ear', '##ci', '##cc', 'did', '##ass', '##ittle', '##way', 'co', 'us', 'little', 'like', 'ad', '##ite', 'day', '##urn', 'pro', '##ought', '##other', 'time', '##fore', 'over', 'dis', '##ade', '##ack', 'how', '##ell', '##ment', 'look', 'great', '##pt', '##ide', '##hing', '##ree', 'about', 'after', '##ice', '##ab', '##wn', 'per', 'know', 'lo', 'upon', 'car', '##ally', 'see', '##ings', 'too', 'again', 'has', 'well', '##ink', 'fl', 'po', 'our', 'str', 'only', 'two', '##ather', '##ked', '##pl', 'hand', '##ount', 'should', '##ud', '##ving', '##oss', '##ves', 'good', '##ire', 'thr', 'pe', 'app', 'pl', 'say', '##ty', '##ions', 'down', '##ile', 'mar', '##ont', 'before', 'every', '##ans', 'old', 'made', '##ang', '##age', 'off', '##ress', 'long', '##ick', 'cr', '##ied', 'fir', 'these', 'bl', 'such', 'where', '##een', '##ber', '##tain', '##ful', 'mu', 'pre', 'ind', 'part', 'sm', '##ro', '##ward', '##ild', '##ft', '##ue', '##ull', 'must', 'under', 'came', 'sc', '##per', '##ated', 'never', 'miss', '##ord', 'bec', 'even', 'fo', '##ness', 'may', 'rem', '##orn', 'way', '##ious', 'spe', '##ect', '##led', 'much', 'mister', 'come', 'res', 'cont', '##ces', '##int', 'back', 'ey', '##ary', '##ff', 'think', 'let', 'first', 'bet', 'ob', 'thought', '##ath', '##ise', '##ced', 'men', 'pla', 'just', 'des', 'mo', 'own', 'gl', '##co', 'ho', '##ip', '##ried', '##ered', 'here', 'comp', 'himself', '##ady', '##iz', 'might', '##ily', 'went', 'seem', 'wat', '##ouse', 'beg', 'sw', '##ons', '##igh', '##oth', 'imp', '##ens', 'through', 'most', 'em', '##iv', 'pres', 'cons', 'bel', '##ave', 'those', '##ac', '##llow', 'ear', 'without', '##ors', 'acc', 'away', 'get', 'make', 'att', 'head', '##ened', 'comm', 'new', 'pass', '##ction', '##red', 'life', '##les', 'jo', '##iff', 'turn', 'house', 'call', 'som', 'still', '##ds', 'many', 'op', 'eyes', '##ix', 'wom', 'being', 'somet', 'found', '##ory', '##ark', 'sl', 'year', '##atter', 'inter', 'shall', '##ign', '##ause', 'night', 'three', '##are', 'la', 'take', 'ret', 'ser', '##cl', 'last', 'while', 'peop', '##ible', 'put', 'nothing', '##ition', '##ase', '##ether', 'work', 'count', '##ng', '##aking', 'same', '##ew', 'wr', 'tell', '##dy', '##vent', '##ult', 'far', 'people', 'young', 'saw', 'yet', '##pect', '##ace', 'dont', 'right', '##ently', 'place', '##less', 'hu', 'once', 'dist', '##air', 'child', 'nat', 'inst', 'te', 'arm', '##ys', 'another', 'though', 'rep', '##ations', 'room', 'end', '##ict', '##ian', 'cour', '##iend', '##ub', 'nor', 'gra', 'happ', 'father', 'friend', 'took', '##gg', 'char', 'set', '##ished', 'supp', 'want', '##ia', '##alk', 'mind', '##thing', 'pers', 'things', 'ac', '##sel', '##cess', 'cap', 'face', 'light', '##ince', 'gen', 'heart', '##ject', '##so', 'ple', '##irl', '##man', '##end', 'missus', 'world', 'sub', '##ents', 'form', 'war', '##ways', 'near', '##fect', 'left', '##ower', 'find', '##av', '##iver', '##der', 'wa', 'asked', 'diff', 'id', '##augh', 'looked', 'king', 'mom', '##lt', '##ange', '##pped', 'thing', 'always', '##sw', '##ical', 'soon', 'mother', 'sat', '##rew', '##ple', 'sur', 'girl', 'eng', '##ling', '##orm', '##den', 'gu', 'yes', '##ertain', 'poss', 'ph', 'answ', 'high', 'seemed', 'el', 'because', 'rel', '##ever', 'why', 'ill', 'love', '##ph', 'follow', 'tra', 'give', '##ual', 'heard', '##ither', '##ters', 'reg', '##aut', 'inf', '##ars', '##ret', 'sir', '##land', '##ched', 'ke', 'something', 'gi', 'ma', '##ock', 'wind', '##ank', 'prop', 'years', 'home', 'going', 'rest', 'vo', '##ning', 'cle', '##ted', 'unt', 'bu', 'conf', 'return', 'feel', 'water', 'four', 'got', 'hands', 'wo', 'each', '##ited', '##cept', 'against', 'few', 'told', 'bre', 'belie', '##orr', 'door', '##ne', 'exp', 'del', 'dr', 'ass', '##ner', 'kind', '##ail', '##ined', 'also', '##ool', 'act', 'beh', '##ush', 'certain', 'side', 'moment', 'hard', '##act', '##most', 'appear', 'min', 'sil', 'hel', 'knew', '##ial', '##ting', '##iness', 'mon', 'having', 'began', 'gener', '##ows', 'pur', 'ter', 'hum', '##ib', 'ref', 'half', '##ream', 'better', '##ates', '##ason', 'among', 'woman', 'done', 'called', 'dra', '##cy', 'enough', '##oub', '##aps', '##ully', 'quite', '##aken', '##gether', 'oh', 'cur', 'god', '##uth', '##ared', 'lar', 'tre', '##ten', '##ps', '##selves', 'inde', 'whole', 'betw', 'inc', '##ru', '##ised', '##ying', 'six', 'eight', 'seen', '##ash', 'small', 'occ', 'between', '##ired', 'pleas', 'col', 'hour', '##ond', 'ste', 'days', 'does', 'morn', 'toward', '##ular', 'add', 'both', '##osed', '##oke', '##ndred', 'hundred', 'sou', 'turned', '##ks', 'matter', '##ense', 'par', 'course', '##ged', '##owed', 'gave', 'ins', 'beaut', 'dear', 'care', '##ures', '##ained', '##te', 'read', 'keep', 'sim', 'ext', 'point', 'open', 'sk', '##ins', '##ating', '##uck', 'poor', '##tered', 'almost', 'es', '##du', 'however', 'sent', 'land', '##ute', '##bo', '##als', 'morning', 'sure', '##xt', 'ev', 'name', 'bla', 'felt', 'met', 'pa', 'whom', 'exc', '##eng', 'white', 'best', '##ier', 'fam', 'until', '##its', 'words', 'hor', 'sle', 'country', '##res', 'stood', '##amp', 'prin', 'stand', '##haps', '##dden', '##ater', 'red', '##aster', 'perhaps', 'thir', 'power', '##enty', 'sun', '##plied', '##ung', '##up', '##ren', 'mean', 'gre', 'lady', 'sudden', '##vel', 'aw', 'myself', 'less', 'herself', '##iet', 'contin', 'use', '##rib', '##ately', '##ned', '##not', 'suff', 'dark', 'unc', 'fact', 'bar', '##med', 'others', 'adv', 'voice', 'round', 'vis', 'need', 'underst', 'together', 'ide', 'brought', 'anything', 'hear', 'lay', 'mil', 'che', 'law', 'wonder', '##od', '##ove', 'present', 'next', 'quest', '##cei', 'till', '##ife', 'replied', '##eter', '##fully', 'sn', 'reach', 'cond', 'fin', 'person', 'wish', 'fall', 'consid', 'help', 'air', 'sy', 'five', 'feet', 'adm', 'har', '##oun', 'indeed', '##iss', 'since', '##ets', 'black', '##ities', 'large', 'full', 'interest', 'themselves', '##ants', '##ene', '##uring', '']\n"
     ]
    }
   ],
   "source": [
    "# opening the file in read mode\n",
    "my_file = open(\"/media/rathna/New Volume/word_piece/tokenizer_libri_wpe_v1004/vocab.txt\", \"r\")\n",
    "  \n",
    "# reading the file\n",
    "data = my_file.read()\n",
    "  \n",
    "# replacing end splitting the text \n",
    "# when newline ('\\n') is seen.\n",
    "vocab = data.split(\"\\n\")\n",
    "print(vocab)\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9a2c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "1000\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '##u', '##g', '##i', '##n', '##o', '##e', '##c', '##t', '##h', '##a', '##r', '##l', '##s', '##v', '##k', '##b', '##d', '##m', '##f', '##p', '##w', '##y', '##z', '##q', '##x', '##j', 'th', 'the', '##er', '##nd', '##in', '##ed', '##ou', '##at', '##en', 'and', '##es', '##or', '##on', 'of', 'to', '##is', '##ing', '##ar', '##it', '##an', '##as', '##ll', 'in', '##re', 'wh', '##om', 'he', 'be', 'ha', '##le', '##ot', '##ic', '##ut', '##ow', 'it', '##ld', 'that', '##ly', 'was', 'sh', '##gh', '##se', '##id', 'on', '##ve', '##ent', '##et', '##im', '##st', '##ion', '##ce', '##ir', '##ith', 'for', 'you', '##al', 'as', '##ay', 'his', '##ur', 'with', '##ter', 'st', '##ch', '##ver', 're', '##ad', 'her', 'an', '##ght', 'is', 'not', 'had', '##am', 'at', '##ct', '##her', '##oo', 'but', '##ess', '##ould', 'fr', 'se', 'pr', 'she', 'we', 'sa', 'su', 'so', '##ill', '##ain', 'him', '##ight', '##ere', 'me', '##all', '##il', '##ke', 'they', '##est', 'de', 'all', '##ich', 'ch', 'by', 'con', '##pp', 'ne', 'my', 'this', '##ome', '##us', 'have', 'li', '##ck', 'which', '##ore', '##ri', '##ul', 'do', 'from', '##th', '##ge', 'up', '##ard', 'or', '##ra', 'were', 'ex', '##ant', 'said', '##nt', 'one', '##os', 'no', '##pe', '##ble', '##ation', 'man', 'who', 'al', '##ers', 'there', '##ous', 'them', '##and', '##ust', '##ie', 'fe', '##ame', 'when', 'their', '##ist', '##ind', '##ast', '##ood', '##lf', '##ong', 'are', '##our', '##em', 'go', '##art', '##out', 'le', 'kn', '##if', 'com', 'would', '##ate', '##ound', 'int', '##ol', 'wor', 'if', 'ab', '##ak', '##op', 'out', '##um', 'br', 'will', '##un', 'mis', 'what', '##ish', '##ap', 'en', '##ough', '##one', '##la', 'ar', '##itt', 'been', '##own', '##reat', 'un', 'tr', '##ity', '##ig', '##ook', '##ive', '##ven', 'then', 'af', 'ro', '##ort', 'sp', 'tw', '##ost', 'qu', '##self', 'fa', '##ery', 'ag', '##el', 'could', 'am', 'im', 'some', '##ake', '##ure', 'any', '##ther', '##nder', '##ence', 'more', 'tim', 'into', '##ep', '##ose', 'ever', '##ies', '##ry', '##fe', '##ag', '##au', '##qu', 'your', '##ved', 'bo', 'other', 'its', 'now', '##ance', 'cl', 'can', 'very', '##ach', 'gr', 'than', '##able', '##ine', '##ear', '##ci', '##cc', 'did', '##ass', '##ittle', '##way', 'co', 'us', 'little', 'like', 'ad', '##ite', 'day', '##urn', 'pro', '##ought', '##other', 'time', '##fore', 'over', 'dis', '##ade', '##ack', 'how', '##ell', '##ment', 'look', 'great', '##pt', '##ide', '##hing', '##ree', 'about', 'after', '##ice', '##ab', '##wn', 'per', 'know', 'lo', 'upon', 'car', '##ally', 'see', '##ings', 'too', 'again', 'has', 'well', '##ink', 'fl', 'po', 'our', 'str', 'only', 'two', '##ather', '##ked', '##pl', 'hand', '##ount', 'should', '##ud', '##ving', '##oss', '##ves', 'good', '##ire', 'thr', 'pe', 'app', 'pl', 'say', '##ty', '##ions', 'down', '##ile', 'mar', '##ont', 'before', 'every', '##ans', 'old', 'made', '##ang', '##age', 'off', '##ress', 'long', '##ick', 'cr', '##ied', 'fir', 'these', 'bl', 'such', 'where', '##een', '##ber', '##tain', '##ful', 'mu', 'pre', 'ind', 'part', 'sm', '##ro', '##ward', '##ild', '##ft', '##ue', '##ull', 'must', 'under', 'came', 'sc', '##per', '##ated', 'never', 'miss', '##ord', 'bec', 'even', 'fo', '##ness', 'may', 'rem', '##orn', 'way', '##ious', 'spe', '##ect', '##led', 'much', 'mister', 'come', 'res', 'cont', '##ces', '##int', 'back', 'ey', '##ary', '##ff', 'think', 'let', 'first', 'bet', 'ob', 'thought', '##ath', '##ise', '##ced', 'men', 'pla', 'just', 'des', 'mo', 'own', 'gl', '##co', 'ho', '##ip', '##ried', '##ered', 'here', 'comp', 'himself', '##ady', '##iz', 'might', '##ily', 'went', 'seem', 'wat', '##ouse', 'beg', 'sw', '##ons', '##igh', '##oth', 'imp', '##ens', 'through', 'most', 'em', '##iv', 'pres', 'cons', 'bel', '##ave', 'those', '##ac', '##llow', 'ear', 'without', '##ors', 'acc', 'away', 'get', 'make', 'att', 'head', '##ened', 'comm', 'new', 'pass', '##ction', '##red', 'life', '##les', 'jo', '##iff', 'turn', 'house', 'call', 'som', 'still', '##ds', 'many', 'op', 'eyes', '##ix', 'wom', 'being', 'somet', 'found', '##ory', '##ark', 'sl', 'year', '##atter', 'inter', 'shall', '##ign', '##ause', 'night', 'three', '##are', 'la', 'take', 'ret', 'ser', '##cl', 'last', 'while', 'peop', '##ible', 'put', 'nothing', '##ition', '##ase', '##ether', 'work', 'count', '##ng', '##aking', 'same', '##ew', 'wr', 'tell', '##dy', '##vent', '##ult', 'far', 'people', 'young', 'saw', 'yet', '##pect', '##ace', 'dont', 'right', '##ently', 'place', '##less', 'hu', 'once', 'dist', '##air', 'child', 'nat', 'inst', 'te', 'arm', '##ys', 'another', 'though', 'rep', '##ations', 'room', 'end', '##ict', '##ian', 'cour', '##iend', '##ub', 'nor', 'gra', 'happ', 'father', 'friend', 'took', '##gg', 'char', 'set', '##ished', 'supp', 'want', '##ia', '##alk', 'mind', '##thing', 'pers', 'things', 'ac', '##sel', '##cess', 'cap', 'face', 'light', '##ince', 'gen', 'heart', '##ject', '##so', 'ple', '##irl', '##man', '##end', 'missus', 'world', 'sub', '##ents', 'form', 'war', '##ways', 'near', '##fect', 'left', '##ower', 'find', '##av', '##iver', '##der', 'wa', 'asked', 'diff', 'id', '##augh', 'looked', 'king', 'mom', '##lt', '##ange', '##pped', 'thing', 'always', '##sw', '##ical', 'soon', 'mother', 'sat', '##rew', '##ple', 'sur', 'girl', 'eng', '##ling', '##orm', '##den', 'gu', 'yes', '##ertain', 'poss', 'ph', 'answ', 'high', 'seemed', 'el', 'because', 'rel', '##ever', 'why', 'ill', 'love', '##ph', 'follow', 'tra', 'give', '##ual', 'heard', '##ither', '##ters', 'reg', '##aut', 'inf', '##ars', '##ret', 'sir', '##land', '##ched', 'ke', 'something', 'gi', 'ma', '##ock', 'wind', '##ank', 'prop', 'years', 'home', 'going', 'rest', 'vo', '##ning', 'cle', '##ted', 'unt', 'bu', 'conf', 'return', 'feel', 'water', 'four', 'got', 'hands', 'wo', 'each', '##ited', '##cept', 'against', 'few', 'told', 'bre', 'belie', '##orr', 'door', '##ne', 'exp', 'del', 'dr', 'ass', '##ner', 'kind', '##ail', '##ined', 'also', '##ool', 'act', 'beh', '##ush', 'certain', 'side', 'moment', 'hard', '##act', '##most', 'appear', 'min', 'sil', 'hel', 'knew', '##ial', '##ting', '##iness', 'mon', 'having', 'began', 'gener', '##ows', 'pur', 'ter', 'hum', '##ib', 'ref', 'half', '##ream', 'better', '##ates', '##ason', 'among', 'woman', 'done', 'called', 'dra', '##cy', 'enough', '##oub', '##aps', '##ully', 'quite', '##aken', '##gether', 'oh', 'cur', 'god', '##uth', '##ared', 'lar', 'tre', '##ten', '##ps', '##selves', 'inde', 'whole', 'betw', 'inc', '##ru', '##ised', '##ying', 'six', 'eight', 'seen', '##ash', 'small', 'occ', 'between', '##ired', 'pleas', 'col', 'hour', '##ond', 'ste', 'days', 'does', 'morn', 'toward', '##ular', 'add', 'both', '##osed', '##oke', '##ndred', 'hundred', 'sou', 'turned', '##ks', 'matter', '##ense', 'par', 'course', '##ged', '##owed', 'gave', 'ins', 'beaut', 'dear', 'care', '##ures', '##ained', '##te', 'read', 'keep', 'sim', 'ext', 'point', 'open', 'sk', '##ins', '##ating', '##uck', 'poor', '##tered', 'almost', 'es', '##du', 'however', 'sent', 'land', '##ute', '##bo', '##als', 'morning', 'sure', '##xt', 'ev', 'name', 'bla', 'felt', 'met', 'pa', 'whom', 'exc', '##eng', 'white', 'best', '##ier', 'fam', 'until', '##its', 'words', 'hor', 'sle', 'country', '##res', 'stood', '##amp', 'prin', 'stand', '##haps', '##dden', '##ater', 'red', '##aster', 'perhaps', 'thir', 'power', '##enty', 'sun', '##plied', '##ung', '##up', '##ren', 'mean', 'gre', 'lady', 'sudden', '##vel', 'aw', 'myself', 'less', 'herself', '##iet', 'contin', 'use', '##rib', '##ately', '##ned', '##not', 'suff', 'dark', 'unc', 'fact', 'bar', '##med', 'others', 'adv', 'voice', 'round', 'vis', 'need', 'underst', 'together', 'ide', 'brought', 'anything', 'hear', 'lay', 'mil', 'che', 'law', 'wonder', '##od', '##ove', 'present', 'next', 'quest', '##cei', 'till', '##ife', 'replied', '##eter', '##fully', 'sn', 'reach', 'cond', 'fin', 'person', 'wish', 'fall', 'consid', 'help', 'air', 'sy', 'five', 'feet', 'adm', 'har', '##oun', 'indeed', '##iss', 'since', '##ets', 'black', '##ities', 'large', 'full', 'interest', 'themselves', '##ants', '##ene', '##uring', ' ']\n"
     ]
    }
   ],
   "source": [
    "vocab = vocab[5:-1]\n",
    "print(len(vocab))\n",
    "vocab = vocab+[' '] # Add apostrophe later\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e465a7",
   "metadata": {},
   "source": [
    "char_set = set()\n",
    "for i in tqdm(range(len(metadata))):\n",
    "    text = metadata.iloc[i,1]\n",
    "    for char in text:\n",
    "        char_set.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ec461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Character mappings : {' ': 0, '##a': 1, '##ab': 2, '##able': 3, '##ac': 4, '##ace': 5, '##ach': 6, '##ack': 7, '##act': 8, '##ad': 9, '##ade': 10, '##ady': 11, '##ag': 12, '##age': 13, '##ail': 14, '##ain': 15, '##ained': 16, '##air': 17, '##ak': 18, '##ake': 19, '##aken': 20, '##aking': 21, '##al': 22, '##alk': 23, '##all': 24, '##ally': 25, '##als': 26, '##am': 27, '##ame': 28, '##amp': 29, '##an': 30, '##ance': 31, '##and': 32, '##ang': 33, '##ange': 34, '##ank': 35, '##ans': 36, '##ant': 37, '##ants': 38, '##ap': 39, '##aps': 40, '##ar': 41, '##ard': 42, '##are': 43, '##ared': 44, '##ark': 45, '##ars': 46, '##art': 47, '##ary': 48, '##as': 49, '##ase': 50, '##ash': 51, '##ason': 52, '##ass': 53, '##ast': 54, '##aster': 55, '##at': 56, '##ate': 57, '##ated': 58, '##ately': 59, '##ater': 60, '##ates': 61, '##ath': 62, '##ather': 63, '##ating': 64, '##ation': 65, '##ations': 66, '##atter': 67, '##au': 68, '##augh': 69, '##ause': 70, '##aut': 71, '##av': 72, '##ave': 73, '##ay': 74, '##b': 75, '##ber': 76, '##ble': 77, '##bo': 78, '##c': 79, '##cc': 80, '##ce': 81, '##ced': 82, '##cei': 83, '##cept': 84, '##ces': 85, '##cess': 86, '##ch': 87, '##ched': 88, '##ci': 89, '##ck': 90, '##cl': 91, '##co': 92, '##ct': 93, '##ction': 94, '##cy': 95, '##d': 96, '##dden': 97, '##den': 98, '##der': 99, '##ds': 100, '##du': 101, '##dy': 102, '##e': 103, '##ear': 104, '##ect': 105, '##ed': 106, '##een': 107, '##el': 108, '##ell': 109, '##em': 110, '##en': 111, '##ence': 112, '##end': 113, '##ene': 114, '##ened': 115, '##eng': 116, '##ens': 117, '##ense': 118, '##ent': 119, '##ently': 120, '##ents': 121, '##enty': 122, '##ep': 123, '##er': 124, '##ere': 125, '##ered': 126, '##ers': 127, '##ertain': 128, '##ery': 129, '##es': 130, '##ess': 131, '##est': 132, '##et': 133, '##eter': 134, '##ether': 135, '##ets': 136, '##ever': 137, '##ew': 138, '##f': 139, '##fe': 140, '##fect': 141, '##ff': 142, '##fore': 143, '##ft': 144, '##ful': 145, '##fully': 146, '##g': 147, '##ge': 148, '##ged': 149, '##gether': 150, '##gg': 151, '##gh': 152, '##ght': 153, '##h': 154, '##haps': 155, '##her': 156, '##hing': 157, '##i': 158, '##ia': 159, '##ial': 160, '##ian': 161, '##ib': 162, '##ible': 163, '##ic': 164, '##ical': 165, '##ice': 166, '##ich': 167, '##ick': 168, '##ict': 169, '##id': 170, '##ide': 171, '##ie': 172, '##ied': 173, '##iend': 174, '##ier': 175, '##ies': 176, '##iet': 177, '##if': 178, '##ife': 179, '##iff': 180, '##ig': 181, '##igh': 182, '##ight': 183, '##ign': 184, '##il': 185, '##ild': 186, '##ile': 187, '##ill': 188, '##ily': 189, '##im': 190, '##in': 191, '##ince': 192, '##ind': 193, '##ine': 194, '##ined': 195, '##iness': 196, '##ing': 197, '##ings': 198, '##ink': 199, '##ins': 200, '##int': 201, '##ion': 202, '##ions': 203, '##ious': 204, '##ip': 205, '##ir': 206, '##ire': 207, '##ired': 208, '##irl': 209, '##is': 210, '##ise': 211, '##ised': 212, '##ish': 213, '##ished': 214, '##iss': 215, '##ist': 216, '##it': 217, '##ite': 218, '##ited': 219, '##ith': 220, '##ither': 221, '##ities': 222, '##ition': 223, '##its': 224, '##itt': 225, '##ittle': 226, '##ity': 227, '##iv': 228, '##ive': 229, '##iver': 230, '##ix': 231, '##iz': 232, '##j': 233, '##ject': 234, '##k': 235, '##ke': 236, '##ked': 237, '##ks': 238, '##l': 239, '##la': 240, '##land': 241, '##ld': 242, '##le': 243, '##led': 244, '##les': 245, '##less': 246, '##lf': 247, '##ling': 248, '##ll': 249, '##llow': 250, '##lt': 251, '##ly': 252, '##m': 253, '##man': 254, '##med': 255, '##ment': 256, '##most': 257, '##n': 258, '##nd': 259, '##nder': 260, '##ndred': 261, '##ne': 262, '##ned': 263, '##ner': 264, '##ness': 265, '##ng': 266, '##ning': 267, '##not': 268, '##nt': 269, '##o': 270, '##ock': 271, '##od': 272, '##oke': 273, '##ol': 274, '##om': 275, '##ome': 276, '##on': 277, '##ond': 278, '##one': 279, '##ong': 280, '##ons': 281, '##ont': 282, '##oo': 283, '##ood': 284, '##ook': 285, '##ool': 286, '##op': 287, '##or': 288, '##ord': 289, '##ore': 290, '##orm': 291, '##orn': 292, '##orr': 293, '##ors': 294, '##ort': 295, '##ory': 296, '##os': 297, '##ose': 298, '##osed': 299, '##oss': 300, '##ost': 301, '##ot': 302, '##oth': 303, '##other': 304, '##ou': 305, '##oub': 306, '##ough': 307, '##ought': 308, '##ould': 309, '##oun': 310, '##ound': 311, '##ount': 312, '##our': 313, '##ous': 314, '##ouse': 315, '##out': 316, '##ove': 317, '##ow': 318, '##owed': 319, '##ower': 320, '##own': 321, '##ows': 322, '##p': 323, '##pe': 324, '##pect': 325, '##per': 326, '##ph': 327, '##pl': 328, '##ple': 329, '##plied': 330, '##pp': 331, '##pped': 332, '##ps': 333, '##pt': 334, '##q': 335, '##qu': 336, '##r': 337, '##ra': 338, '##re': 339, '##ream': 340, '##reat': 341, '##red': 342, '##ree': 343, '##ren': 344, '##res': 345, '##ress': 346, '##ret': 347, '##rew': 348, '##ri': 349, '##rib': 350, '##ried': 351, '##ro': 352, '##ru': 353, '##ry': 354, '##s': 355, '##se': 356, '##sel': 357, '##self': 358, '##selves': 359, '##so': 360, '##st': 361, '##sw': 362, '##t': 363, '##tain': 364, '##te': 365, '##ted': 366, '##ten': 367, '##ter': 368, '##tered': 369, '##ters': 370, '##th': 371, '##ther': 372, '##thing': 373, '##ting': 374, '##ty': 375, '##u': 376, '##ual': 377, '##ub': 378, '##uck': 379, '##ud': 380, '##ue': 381, '##ul': 382, '##ular': 383, '##ull': 384, '##ully': 385, '##ult': 386, '##um': 387, '##un': 388, '##ung': 389, '##up': 390, '##ur': 391, '##ure': 392, '##ures': 393, '##uring': 394, '##urn': 395, '##us': 396, '##ush': 397, '##ust': 398, '##ut': 399, '##ute': 400, '##uth': 401, '##v': 402, '##ve': 403, '##ved': 404, '##vel': 405, '##ven': 406, '##vent': 407, '##ver': 408, '##ves': 409, '##ving': 410, '##w': 411, '##ward': 412, '##way': 413, '##ways': 414, '##wn': 415, '##x': 416, '##xt': 417, '##y': 418, '##ying': 419, '##ys': 420, '##z': 421, 'a': 422, 'ab': 423, 'about': 424, 'ac': 425, 'acc': 426, 'act': 427, 'ad': 428, 'add': 429, 'adm': 430, 'adv': 431, 'af': 432, 'after': 433, 'ag': 434, 'again': 435, 'against': 436, 'air': 437, 'al': 438, 'all': 439, 'almost': 440, 'also': 441, 'always': 442, 'am': 443, 'among': 444, 'an': 445, 'and': 446, 'another': 447, 'answ': 448, 'any': 449, 'anything': 450, 'app': 451, 'appear': 452, 'ar': 453, 'are': 454, 'arm': 455, 'as': 456, 'asked': 457, 'ass': 458, 'at': 459, 'att': 460, 'aw': 461, 'away': 462, 'b': 463, 'back': 464, 'bar': 465, 'be': 466, 'beaut': 467, 'bec': 468, 'because': 469, 'been': 470, 'before': 471, 'beg': 472, 'began': 473, 'beh': 474, 'being': 475, 'bel': 476, 'belie': 477, 'best': 478, 'bet': 479, 'better': 480, 'betw': 481, 'between': 482, 'bl': 483, 'bla': 484, 'black': 485, 'bo': 486, 'both': 487, 'br': 488, 'bre': 489, 'brought': 490, 'bu': 491, 'but': 492, 'by': 493, 'c': 494, 'call': 495, 'called': 496, 'came': 497, 'can': 498, 'cap': 499, 'car': 500, 'care': 501, 'certain': 502, 'ch': 503, 'char': 504, 'che': 505, 'child': 506, 'cl': 507, 'cle': 508, 'co': 509, 'col': 510, 'com': 511, 'come': 512, 'comm': 513, 'comp': 514, 'con': 515, 'cond': 516, 'conf': 517, 'cons': 518, 'consid': 519, 'cont': 520, 'contin': 521, 'could': 522, 'count': 523, 'country': 524, 'cour': 525, 'course': 526, 'cr': 527, 'cur': 528, 'd': 529, 'dark': 530, 'day': 531, 'days': 532, 'de': 533, 'dear': 534, 'del': 535, 'des': 536, 'did': 537, 'diff': 538, 'dis': 539, 'dist': 540, 'do': 541, 'does': 542, 'done': 543, 'dont': 544, 'door': 545, 'down': 546, 'dr': 547, 'dra': 548, 'e': 549, 'each': 550, 'ear': 551, 'eight': 552, 'el': 553, 'em': 554, 'en': 555, 'end': 556, 'eng': 557, 'enough': 558, 'es': 559, 'ev': 560, 'even': 561, 'ever': 562, 'every': 563, 'ex': 564, 'exc': 565, 'exp': 566, 'ext': 567, 'ey': 568, 'eyes': 569, 'f': 570, 'fa': 571, 'face': 572, 'fact': 573, 'fall': 574, 'fam': 575, 'far': 576, 'father': 577, 'fe': 578, 'feel': 579, 'feet': 580, 'felt': 581, 'few': 582, 'fin': 583, 'find': 584, 'fir': 585, 'first': 586, 'five': 587, 'fl': 588, 'fo': 589, 'follow': 590, 'for': 591, 'form': 592, 'found': 593, 'four': 594, 'fr': 595, 'friend': 596, 'from': 597, 'full': 598, 'g': 599, 'gave': 600, 'gen': 601, 'gener': 602, 'get': 603, 'gi': 604, 'girl': 605, 'give': 606, 'gl': 607, 'go': 608, 'god': 609, 'going': 610, 'good': 611, 'got': 612, 'gr': 613, 'gra': 614, 'gre': 615, 'great': 616, 'gu': 617, 'h': 618, 'ha': 619, 'had': 620, 'half': 621, 'hand': 622, 'hands': 623, 'happ': 624, 'har': 625, 'hard': 626, 'has': 627, 'have': 628, 'having': 629, 'he': 630, 'head': 631, 'hear': 632, 'heard': 633, 'heart': 634, 'hel': 635, 'help': 636, 'her': 637, 'here': 638, 'herself': 639, 'high': 640, 'him': 641, 'himself': 642, 'his': 643, 'ho': 644, 'home': 645, 'hor': 646, 'hour': 647, 'house': 648, 'how': 649, 'however': 650, 'hu': 651, 'hum': 652, 'hundred': 653, 'i': 654, 'id': 655, 'ide': 656, 'if': 657, 'ill': 658, 'im': 659, 'imp': 660, 'in': 661, 'inc': 662, 'ind': 663, 'inde': 664, 'indeed': 665, 'inf': 666, 'ins': 667, 'inst': 668, 'int': 669, 'inter': 670, 'interest': 671, 'into': 672, 'is': 673, 'it': 674, 'its': 675, 'j': 676, 'jo': 677, 'just': 678, 'k': 679, 'ke': 680, 'keep': 681, 'kind': 682, 'king': 683, 'kn': 684, 'knew': 685, 'know': 686, 'l': 687, 'la': 688, 'lady': 689, 'land': 690, 'lar': 691, 'large': 692, 'last': 693, 'law': 694, 'lay': 695, 'le': 696, 'left': 697, 'less': 698, 'let': 699, 'li': 700, 'life': 701, 'light': 702, 'like': 703, 'little': 704, 'lo': 705, 'long': 706, 'look': 707, 'looked': 708, 'love': 709, 'm': 710, 'ma': 711, 'made': 712, 'make': 713, 'man': 714, 'many': 715, 'mar': 716, 'matter': 717, 'may': 718, 'me': 719, 'mean': 720, 'men': 721, 'met': 722, 'might': 723, 'mil': 724, 'min': 725, 'mind': 726, 'mis': 727, 'miss': 728, 'missus': 729, 'mister': 730, 'mo': 731, 'mom': 732, 'moment': 733, 'mon': 734, 'more': 735, 'morn': 736, 'morning': 737, 'most': 738, 'mother': 739, 'mu': 740, 'much': 741, 'must': 742, 'my': 743, 'myself': 744, 'n': 745, 'name': 746, 'nat': 747, 'ne': 748, 'near': 749, 'need': 750, 'never': 751, 'new': 752, 'next': 753, 'night': 754, 'no': 755, 'nor': 756, 'not': 757, 'nothing': 758, 'now': 759, 'o': 760, 'ob': 761, 'occ': 762, 'of': 763, 'off': 764, 'oh': 765, 'old': 766, 'on': 767, 'once': 768, 'one': 769, 'only': 770, 'op': 771, 'open': 772, 'or': 773, 'other': 774, 'others': 775, 'our': 776, 'out': 777, 'over': 778, 'own': 779, 'p': 780, 'pa': 781, 'par': 782, 'part': 783, 'pass': 784, 'pe': 785, 'peop': 786, 'people': 787, 'per': 788, 'perhaps': 789, 'pers': 790, 'person': 791, 'ph': 792, 'pl': 793, 'pla': 794, 'place': 795, 'ple': 796, 'pleas': 797, 'po': 798, 'point': 799, 'poor': 800, 'poss': 801, 'power': 802, 'pr': 803, 'pre': 804, 'pres': 805, 'present': 806, 'prin': 807, 'pro': 808, 'prop': 809, 'pur': 810, 'put': 811, 'q': 812, 'qu': 813, 'quest': 814, 'quite': 815, 'r': 816, 're': 817, 'reach': 818, 'read': 819, 'red': 820, 'ref': 821, 'reg': 822, 'rel': 823, 'rem': 824, 'rep': 825, 'replied': 826, 'res': 827, 'rest': 828, 'ret': 829, 'return': 830, 'right': 831, 'ro': 832, 'room': 833, 'round': 834, 's': 835, 'sa': 836, 'said': 837, 'same': 838, 'sat': 839, 'saw': 840, 'say': 841, 'sc': 842, 'se': 843, 'see': 844, 'seem': 845, 'seemed': 846, 'seen': 847, 'sent': 848, 'ser': 849, 'set': 850, 'sh': 851, 'shall': 852, 'she': 853, 'should': 854, 'side': 855, 'sil': 856, 'sim': 857, 'since': 858, 'sir': 859, 'six': 860, 'sk': 861, 'sl': 862, 'sle': 863, 'sm': 864, 'small': 865, 'sn': 866, 'so': 867, 'som': 868, 'some': 869, 'somet': 870, 'something': 871, 'soon': 872, 'sou': 873, 'sp': 874, 'spe': 875, 'st': 876, 'stand': 877, 'ste': 878, 'still': 879, 'stood': 880, 'str': 881, 'su': 882, 'sub': 883, 'such': 884, 'sudden': 885, 'suff': 886, 'sun': 887, 'supp': 888, 'sur': 889, 'sure': 890, 'sw': 891, 'sy': 892, 't': 893, 'take': 894, 'te': 895, 'tell': 896, 'ter': 897, 'th': 898, 'than': 899, 'that': 900, 'the': 901, 'their': 902, 'them': 903, 'themselves': 904, 'then': 905, 'there': 906, 'these': 907, 'they': 908, 'thing': 909, 'things': 910, 'think': 911, 'thir': 912, 'this': 913, 'those': 914, 'though': 915, 'thought': 916, 'thr': 917, 'three': 918, 'through': 919, 'till': 920, 'tim': 921, 'time': 922, 'to': 923, 'together': 924, 'told': 925, 'too': 926, 'took': 927, 'toward': 928, 'tr': 929, 'tra': 930, 'tre': 931, 'turn': 932, 'turned': 933, 'tw': 934, 'two': 935, 'u': 936, 'un': 937, 'unc': 938, 'under': 939, 'underst': 940, 'unt': 941, 'until': 942, 'up': 943, 'upon': 944, 'us': 945, 'use': 946, 'v': 947, 'very': 948, 'vis': 949, 'vo': 950, 'voice': 951, 'w': 952, 'wa': 953, 'want': 954, 'war': 955, 'was': 956, 'wat': 957, 'water': 958, 'way': 959, 'we': 960, 'well': 961, 'went': 962, 'were': 963, 'wh': 964, 'what': 965, 'when': 966, 'where': 967, 'which': 968, 'while': 969, 'white': 970, 'who': 971, 'whole': 972, 'whom': 973, 'why': 974, 'will': 975, 'wind': 976, 'wish': 977, 'with': 978, 'without': 979, 'wo': 980, 'wom': 981, 'woman': 982, 'wonder': 983, 'wor': 984, 'words': 985, 'work': 986, 'world': 987, 'would': 988, 'wr': 989, 'x': 990, 'y': 991, 'year': 992, 'years': 993, 'yes': 994, 'yet': 995, 'you': 996, 'young': 997, 'your': 998, 'z': 999}\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(vocab)\n",
    "num_embeddings = len(vocab)\n",
    "print(num_embeddings)\n",
    "vocab_ids = [int(i) for i in range(num_embeddings)]\n",
    "vocab_dict = dict(zip(vocab,vocab_ids))\n",
    "print(f\"Character mappings : {vocab_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101e4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {\n",
    "        \"sample_rate\":16000,\n",
    "        \"n_mels\":80, #as per reference\n",
    "    }\n",
    "\n",
    "# time_masks = [torchaudio.transforms.TimeMasking(time_mask_param=15, p=0.05) for _ in range(10)]\n",
    "# train_transform = nn.Sequential(\n",
    "#    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=80, hop_length=160), #80 filter banks, 25ms window size, 10ms hop\n",
    "#    torchaudio.transforms.FrequencyMasking(freq_mask_param=27),\n",
    "#    *time_masks,\n",
    "#  )\n",
    "train_transform = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=80, hop_length=160)\n",
    "validation_transform = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=80, hop_length=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84fe4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_word(word):\n",
    "    tokens = []\n",
    "    while len(word) > 0:\n",
    "        i = len(word)\n",
    "        while i > 0 and word[:i] not in vocab:\n",
    "            i -= 1\n",
    "        if i == 0:\n",
    "            return [\"[UNK]\"]\n",
    "        tokens.append(word[:i])\n",
    "        word = word[i:]\n",
    "        if len(word) > 0:\n",
    "            word = f\"##{word}\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05430183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_piece_tokenizer(text):\n",
    "    text_list = re.split(\" \", text)\n",
    "    new_list = []\n",
    "    for i in range(0,len(text_list)-1):\n",
    "        new_list.append(text_list[i])\n",
    "        new_list.append(' ')\n",
    "    new_list.append(text_list[-1])   \n",
    "    #print(new_list)\n",
    "    encoded_words = []\n",
    "    for word in new_list:\n",
    "        encoded_words += encode_word(word)\n",
    "    #print(encoded_words)\n",
    "    mapped_words = [vocab_dict[word_piece] for word_piece in encoded_words]\n",
    "    return mapped_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13b031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe609522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    The Class will act as the container for our dataset. It will take your dataframe, the root path, and also the transform function for transforming the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_frame, char_dict, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        #self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        #self.max_transcript_len = N\n",
    "        self.char_dict = char_dict\n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return the observation based on an index. Ex. dataset[0] will return the first element from the dataset, in this case the image and the label.\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        file_path = self.data_frame.iloc[idx, 0]\n",
    "        waveform, sample_rate = torchaudio.load(file_path, normalize = True)\n",
    "        if sample_rate!=16000:\n",
    "            waveform = transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
    "        mel_spec = self.transform(waveform) # (batch, n_mels, time)\n",
    "        mel_spec = mel_spec.squeeze(0).transpose(0,1)  # (time, n_mels)\n",
    "        mel_spec_len = ((mel_spec.shape[0] - 1) // 2 - 1) // 2\n",
    "        \n",
    "        transcript = self.data_frame.iloc[idx,1]\n",
    "        transcript = str(transcript)\n",
    "        input_transcript_list = word_piece_tokenizer(transcript)\n",
    "#         for char in transcript:\n",
    "#             input_transcript_list.append(self.char_dict[char])\n",
    "        \n",
    "        label_tensor = torch.LongTensor(input_transcript_list)\n",
    "        label_len = len(input_transcript_list)\n",
    "    \n",
    "        return mel_spec, label_tensor, mel_spec_len, label_len, transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedafc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(len(metadata)*0.99)\n",
    "# dev_size = len(metadata) - train_size\n",
    "\n",
    "# if not os.path.exists(metadata_path):\n",
    "#     metadata_train = metadata[:train_size]\n",
    "#     metadata_dev   = metadata[train_size:]\n",
    "#     metadata_train.to_csv(\"lj_metadata_train.tsv\", sep='\\t', header=False, index=False)\n",
    "#     metadata_dev.to_csv(\"lj_metadata_test.tsv\", sep='\\t', header=False, index=False)\n",
    "# else:\n",
    "#     print(\"Using existing metadata!\")\n",
    "#     metadata_train = pd.read_csv(\"lj_metadata_train.tsv\", sep='\\t', header=None, encoding='utf-8')\n",
    "#     metadata_dev  = pd.read_csv(\"lj_metadata_test.tsv\", sep='\\t', header=None, encoding='utf-8')\n",
    "    \n",
    "trainset = MyDataset(metadata_train, vocab_dict, transform=train_transform)\n",
    "devset = MyDataset(metadata_dev, vocab_dict, transform=validation_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = TRAIN_BS, shuffle = True, collate_fn = collate_batch, drop_last=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "devloader  = torch.utils.data.DataLoader(devset,  batch_size = TEST_BS, shuffle = True, collate_fn = collate_batch, drop_last=True, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1840b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params = {\n",
    "    \"d_input\": 80,\n",
    "    \"d_model\": 144,\n",
    "    \"num_layers\": 16,\n",
    "    \"conv_kernel_size\": 32,\n",
    "    \"dropout\": 0.1,\n",
    "    \"num_heads\": 4\n",
    "}\n",
    "\n",
    "decoder_params = {\n",
    "    \"d_encoder\": 144,\n",
    "    \"d_decoder\": 320,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_classes\":len(vocab)+1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73500ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ConformerEncoder(\n",
    "                      d_input=encoder_params['d_input'],\n",
    "                      d_model=encoder_params['d_model'],\n",
    "                      num_layers=encoder_params['num_layers'],\n",
    "                      conv_kernel_size=encoder_params['conv_kernel_size'], \n",
    "                      dropout=encoder_params['dropout'],\n",
    "                      num_heads=encoder_params['num_heads']\n",
    "                    )\n",
    "  \n",
    "decoder = LSTMDecoder(\n",
    "                  d_encoder=decoder_params['d_encoder'], \n",
    "                  d_decoder=decoder_params['d_decoder'], \n",
    "                  num_layers=decoder_params['num_layers'],\n",
    "                  num_classes= decoder_params['num_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a697ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder.to(DEVICE)\n",
    "decoder = decoder.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e6b6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_decoder =  GreedyCharacterDecoder().eval()\n",
    "criterion = nn.CTCLoss(blank=len(vocab), zero_infinity=True)\n",
    "optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=5e-4, betas=(.9, .98), eps = 1e-09, weight_decay=1e-6)\n",
    "scheduler = TransformerLrScheduler(optimizer, encoder_params['d_model'], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23f5f082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder - num_params: 10.13M,  size: 38.66MB\n",
      "Decoder - num_params: 0.92M,  size: 3.5MB\n"
     ]
    }
   ],
   "source": [
    "model_size(encoder, 'Encoder')\n",
    "model_size(decoder, 'Decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64f53f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d832c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(DEVICE)\n",
    "criterion = criterion.to(DEVICE)\n",
    "char_decoder = char_decoder.to(DEVICE)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "checkpoint_load_path = \"conf_s_libri_best_wer.pt\"\n",
    "\n",
    "if(os.path.exists(checkpoint_load_path)):\n",
    "    start_epoch, best_loss, best_wer = load_checkpoint(encoder, decoder, optimizer, scheduler, checkpoint_load_path, DEVICE)\n",
    "    print(f'Resuming training from checkpoint starting at epoch {start_epoch}.')\n",
    "    print(f'Current model WER : {best_wer}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dac388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, char_decoder, optimizer, scheduler, criterion, grad_scaler, train_loader, device): \n",
    "    wer = WordErrorRate()\n",
    "    cer = CharErrorRate()\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    avg_loss = 0\n",
    "    avg_wer = 0\n",
    "    avg_cer = 0\n",
    "    batch_count = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch_count += 1\n",
    "        scheduler.step()\n",
    "        gc.collect()\n",
    "        spectrograms, labels, input_lengths, label_lengths, references, mask = batch \n",
    "\n",
    "        spectrograms = spectrograms.squeeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        input_lengths = torch.tensor(input_lengths).to(device)\n",
    "        label_lengths = torch.tensor(label_lengths).to(device)\n",
    "        mask = mask.to(device)\n",
    "    \n",
    "        outputs, _ = encoder(spectrograms, mask)\n",
    "        outputs, _ = decoder(outputs)\n",
    "        loss = criterion(F.log_softmax(outputs, dim=-1).transpose(0, 1), labels, input_lengths, label_lengths)\n",
    "        #loss.backward()\n",
    "        \n",
    "        grad_scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), 0.1)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), 0.1)\n",
    "        #if (i+1) % args.accumulate_iters == 0:\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        #avg_loss.update(loss.detach().item())\n",
    "        \n",
    "        #use for small datasets\n",
    "        \n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss += loss.detach().item()\n",
    "        \n",
    "        inds = char_decoder(outputs.detach())\n",
    "        # print(\"train shape:\",inds.shape)\n",
    "        predictions = []\n",
    "        for sample in inds:\n",
    "            #print(sample.shape)\n",
    "            predictions.append(int_to_text(sample, len(vocab), vocab))\n",
    "        avg_wer += wer(predictions, references) * 100\n",
    "        avg_cer += cer(predictions, references) * 100\n",
    "\n",
    "    avg_loss = avg_loss/batch_count\n",
    "    avg_wer = avg_wer/batch_count\n",
    "    avg_cer = avg_cer/batch_count\n",
    "    print(f'Avg WER: {avg_wer}%, Avg Loss: {avg_loss}')  \n",
    "    for i in range(5):\n",
    "        print('Prediction: ', predictions[i])\n",
    "        print('Reference: ', references[i])\n",
    "    \n",
    "    # Print metrics and predictions \n",
    "    del spectrograms, labels, input_lengths, label_lengths, references, outputs, inds, predictions\n",
    "    return avg_wer, avg_cer, avg_loss\n",
    "    \n",
    "def validate(encoder, decoder, char_decoder, criterion, test_loader, device):\n",
    "    ''' Evaluate model on test dataset. '''\n",
    "\n",
    "    wer = WordErrorRate()\n",
    "    cer = CharErrorRate()\n",
    "        \n",
    "    avg_loss = 0\n",
    "    avg_wer = 0\n",
    "    batch_count = 0\n",
    "    avg_cer = 0\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    for batch in tqdm(test_loader):\n",
    "        gc.collect()\n",
    "        batch_count += 1\n",
    "        spectrograms, labels, input_lengths, label_lengths, references, mask = batch \n",
    "  \n",
    "    # Move to GPU\n",
    "        spectrograms = spectrograms.to(device)\n",
    "        labels = labels.to(device)\n",
    "        input_lengths = torch.tensor(input_lengths).to(device)\n",
    "        label_lengths = torch.tensor(label_lengths).to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = encoder(spectrograms, mask)\n",
    "            outputs, _ = decoder(outputs)\n",
    "            loss = criterion(F.log_softmax(outputs, dim=-1).transpose(0, 1), labels, input_lengths, label_lengths)\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            inds = char_decoder(outputs.detach())\n",
    "            # print(\"validation shape:\", inds.shape)\n",
    "            predictions = []\n",
    "            for sample in inds:\n",
    "                predictions.append(int_to_text(sample, len(vocab), vocab))\n",
    "\n",
    "            avg_wer += wer(predictions, references) * 100\n",
    "            avg_cer += cer(predictions, references) * 100\n",
    "    print(\".............................TEST PREDICTIONS...........................\")\n",
    "    for i in range(5):\n",
    "        print('Prediction: ', predictions[i])\n",
    "        print('Reference: ', references[i])\n",
    "    print(\"************************************************************************\")\n",
    "    \n",
    "    return avg_wer/batch_count, avg_cer/batch_count, loss/batch_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3be84cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_path = \"conf_s_libri_chk.pt\"\n",
    "best_loss_save_path = \"conf_s_libri_best_loss.pt\"\n",
    "best_wer_save_path = \"conf_s_libri_best_wer.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "297b12ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mixed Precision\n",
      "Epoch : 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6224/6224 [1:06:06<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg WER: 98.96968078613281%, Avg Loss: 4.337714385059315\n",
      "Prediction:  and r c r r r r r r r r c r c c r r r r\n",
      "Reference:  aunt mauds appreciation of that to night was indeed managerial and the performers own contribution fairly that of the faultless soldier on parade densher saw himself for the moment as in his purchased stall at the play\n",
      "Prediction:  and r r r r r c r r r r r to r r r r c\n",
      "Reference:  then he scraped its claws with a penknife sharpened its nails fitted it with spurs of sharp steel spat on its head spat on its neck anointed it with spittle as they used to rub oil over athletes then set it down in the pit a redoubtable champion exclaiming\n",
      "Prediction:  and r r r r r c r c r r r r r r r r r c\n",
      "Reference:  while tom rawle quietly chuckling at the fat lads misfortune aided him to his feet down flat said mackinson again as he discerned several shadows moving across a space a considerable distance to the north of them\n",
      "Prediction:  and r r r r r r r r r r r r r r r r r\n",
      "Reference:  and opened fire at the same time the rest of the posse divided shelled him from two side streets up which they were cautiously manoeuvring from a well executed detour the first volley broke the lock of one of calliopes guns\n",
      "Prediction:  and r r r r r c r r r r c c r r r c r c\n",
      "Reference:  a man stood awaiting us at the waters edge i fancied while we were still far off that i saw some other and very grotesque looking creatures scuttle into the bushes upon the slope but i saw nothing of these as we drew nearer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 121/121 [00:35<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................TEST PREDICTIONS...........................\n",
      "Prediction:  and r \n",
      "Reference:  i am not allowed to perform magic except for my own amusement he told his visitors as he lighted a pipe with a crooked stem and began to smoke\n",
      "Prediction:  and c\n",
      "Reference:  one thinks one hears hydras talking\n",
      "Prediction:  and the\n",
      "Reference:  anders face grew red\n",
      "Prediction:  and r\n",
      "Reference:  he returned carrying his jumping shoes which are provided as you are aware with several sharp spikes\n",
      "Prediction:  and r \n",
      "Reference:  i address him in italian and he answers very wittily but his way of speaking makes me smile and i tell him why\n",
      "************************************************************************\n",
      "Epoch 0 - Valid WER: 97.4828872680664%, Valid CER: 94.58130645751953%, Valid Loss: 0.042391058057546616, Train WER: 98.96968078613281%, Train CER: 88.01534271240234%, Train Loss: 4.337714385059315\n",
      "Validation loss improved, saving best model.\n",
      "Saving checkpoint at epoch:1\n",
      "Validation WER improved, saving best model.\n",
      "Epoch : 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6224/6224 [1:00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg WER: 98.22488403320312%, Avg Loss: 3.8466739589803325\n",
      "Prediction:  and r r r r de r r r r r r r r r d d\n",
      "Reference:  when at last he got out of the house he saw with disgust the confounded policeman still standing on the pavement can he be waiting for me thought mister vladimir looking up and down for some signs of a hansom\n",
      "Prediction:  and r r r a r r r r r r r d r r r d\n",
      "Reference:  what if i do forbid it she walked a little forward leaving the carnation bed and halted under the shade of the dark cedar tree her heart and colour alike fading mister yorke followed and stood before her william i must do my duty\n",
      "Prediction:  and  r r r r r r r r  r r r d d d\n",
      "Reference:  every one has his own manner of growth and we have ours answered the young beeches this is the way its done where we come from and we are perhaps as good as you are\n",
      "Prediction:  and r r r de r r r r r r r r r r d r\n",
      "Reference:  broke out of him of a sudden and he flung up his arms like a lost spirit the monk took the helm in a tired way he did not seem much astonished for he came from an ignorant part of the world\n",
      "Prediction:  and r r r r r r r r r r r r r r r\n",
      "Reference:  and told about her sister ellen had suggested that maybe he could get her sister to take him to board to this day julia cloud has never decided whether ellen really thought julia would take a professor from the college to board or whether she just sent him there as a joke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 121/121 [00:34<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................TEST PREDICTIONS...........................\n",
      "Prediction:  and r\n",
      "Reference:  one of us always remains on board while the other is on shore\n",
      "Prediction:  and r\n",
      "Reference:  the proof was in three long slips i had left them all together\n",
      "Prediction:  and r r\n",
      "Reference:  asked phronsie in intense interest slipping down out of pollys arms and crowding up close to jaspers side\n",
      "Prediction:  and          \n",
      "Reference:  his housekeeper had the management of everything she never allowed him to be in need of anything and she gave no account of his money which she kept altogether because he never asked her to render any accounts\n",
      "Prediction:  and r     \n",
      "Reference:  by quick marches through these inaccessible mountains that general freed himself from the superior forces of the covenanters\n",
      "************************************************************************\n",
      "Epoch 1 - Valid WER: 97.35359954833984%, Valid CER: 92.20494079589844%, Valid Loss: 0.040320757776498795, Train WER: 98.22488403320312%, Train CER: 83.72227478027344%, Train Loss: 3.8466739589803325\n",
      "Validation loss improved, saving best model.\n",
      "Validation WER improved, saving best model.\n",
      "Epoch : 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                     | 369/6224 [03:16<51:50,  1.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 25\u001b[0m\n\u001b[1;32m     16\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#variational noise for regularization - COMMENTING ON MAY 19\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     add_model_noise(encoder, std=variational_noise_std, gpu=True)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     add_model_noise(decoder, std=variational_noise_std, gpu=True)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Train/Validation loops\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#wer, cer, loss = train(encoder_parallel, decoder_parallel, char_decoder, optimizer, scheduler, criterion, trainloader, DEVICE) \u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     wer, cer, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_scaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     26\u001b[0m     valid_wer, valid_cer, valid_loss \u001b[38;5;241m=\u001b[39m validate(encoder, decoder, char_decoder, criterion, devloader, DEVICE)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Valid WER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_wer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Valid CER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_cer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Valid Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train WER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Train CER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)  \n",
      "Cell \u001b[0;32mIn [20], line 51\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, char_decoder, optimizer, scheduler, criterion, grad_scaler, train_loader, device)\u001b[0m\n\u001b[1;32m     49\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(int_to_text(sample, \u001b[38;5;28mlen\u001b[39m(vocab), vocab))\n\u001b[1;32m     50\u001b[0m     avg_wer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m wer(predictions, references) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 51\u001b[0m     avg_cer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     53\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m avg_loss\u001b[38;5;241m/\u001b[39mbatch_count\n\u001b[1;32m     54\u001b[0m avg_wer \u001b[38;5;241m=\u001b[39m avg_wer\u001b[38;5;241m/\u001b[39mbatch_count\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.9/site-packages/torchmetrics/metric.py:234\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.9/site-packages/torchmetrics/metric.py:300\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.9/site-packages/torchmetrics/metric.py:388\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 388\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.9/site-packages/torchmetrics/text/cer.py:79\u001b[0m, in \u001b[0;36mCharErrorRate.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]], target: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124;03m\"\"\"Store references/predictions for computing Character Error Rate scores.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m        preds: Transcription(s) to score as a string or list of strings\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m        target: Reference(s) for each speech input as a string or list of strings\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     errors, total \u001b[38;5;241m=\u001b[39m \u001b[43m_cer_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m errors\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.9/site-packages/torchmetrics/functional/text/cer.py:46\u001b[0m, in \u001b[0;36m_cer_update\u001b[0;34m(preds, target)\u001b[0m\n\u001b[1;32m     44\u001b[0m     pred_tokens \u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m     45\u001b[0m     tgt_tokens \u001b[38;5;241m=\u001b[39m tgt\n\u001b[0;32m---> 46\u001b[0m     errors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m_edit_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtgt_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tgt_tokens)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m errors, total\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.9/site-packages/torchmetrics/functional/text/helper.py:352\u001b[0m, in \u001b[0;36m_edit_distance\u001b[0;34m(prediction_tokens, reference_tokens)\u001b[0m\n\u001b[1;32m    350\u001b[0m             dp[i][j] \u001b[38;5;241m=\u001b[39m dp[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m][j \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m             dp[i][j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dp[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "best_wer = float('inf')\n",
    "optimizer.zero_grad()\n",
    "\n",
    "use_amp = True\n",
    "variational_noise_std = 0.0001\n",
    "\n",
    "# Mixed Precision Setup\n",
    "if use_amp:\n",
    "    print('Using Mixed Precision')\n",
    "grad_scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    print(f\"Epoch : {epoch+1}/{EPOCHS}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    #variational noise for regularization - COMMENTING ON MAY 19\n",
    "#     add_model_noise(encoder, std=variational_noise_std, gpu=True)\n",
    "#     add_model_noise(decoder, std=variational_noise_std, gpu=True)\n",
    "\n",
    "    \n",
    "    # Train/Validation loops\n",
    "    #wer, cer, loss = train(encoder_parallel, decoder_parallel, char_decoder, optimizer, scheduler, criterion, trainloader, DEVICE) \n",
    "    wer, cer, loss = train(encoder, decoder, char_decoder, optimizer, scheduler, criterion, grad_scaler, trainloader, DEVICE) \n",
    "    valid_wer, valid_cer, valid_loss = validate(encoder, decoder, char_decoder, criterion, devloader, DEVICE)\n",
    "    print(f'Epoch {epoch} - Valid WER: {valid_wer}%, Valid CER: {valid_cer}%, Valid Loss: {valid_loss}, Train WER: {wer}%, Train CER: {cer}%, Train Loss: {loss}')  \n",
    "    \n",
    "    # Save best model\n",
    "    if valid_loss <= best_loss:\n",
    "        print('Validation loss improved, saving best model.')\n",
    "        best_loss = valid_loss\n",
    "        save_checkpoint(encoder, decoder, optimizer, scheduler, valid_loss, epoch+1, best_loss_save_path, valid_wer, valid_cer, vocab_dict)\n",
    "    \n",
    "    if epoch%3==0:\n",
    "        print(f'Saving checkpoint at epoch:{epoch+1}')\n",
    "        save_checkpoint(encoder, decoder, optimizer, scheduler, valid_loss, epoch+1, checkpoint_save_path, valid_wer, valid_cer, vocab_dict)\n",
    "    \n",
    "    if valid_wer <= best_wer:\n",
    "        print(f\"Validation WER improved, saving best model.\")\n",
    "        best_wer = valid_wer\n",
    "        save_checkpoint(encoder, decoder, optimizer, scheduler, valid_loss, epoch+1, best_wer_save_path, valid_wer, valid_cer, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a49da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
